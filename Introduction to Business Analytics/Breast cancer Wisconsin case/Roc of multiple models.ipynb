# -*- coding: utf-8 -*-

%matplotlib inline
import matplotlib as plt
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np
from sklearn import neighbors
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler 
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.neighbors import KNeighborsClassifier 
from sklearn.metrics import roc_curve
from sklearn.metrics import auc

"LOAD, FORMAT, AND CLEAN DATA"
url=r'http://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.data'
df = pd.read_csv(url, header=None) 

colnames=["id","diagnosis","radius_mean","texture_mean","perimeter_mean","area_mean","smoothness_mean","compactness_mean","concavity_mean","concave points_mean","symmetry_mean","fractal_dimension_mean","radius_se","texture_se","perimeter_se","area_se","smoothness_se","compactness_se","concavity_se","concave points_se","symmetry_se","fractal_dimension_se","radius_worst","texture_worst","perimeter_worst","area_worst","smoothness_worst","compactness_worst","concavity_worst","concave points_worst","symmetry_worst","fractal_dimension_worst"]
df.columns=colnames

#creating dummy variable for diagnosis where Malignant=1 and Benign=0
df['target']=((df['diagnosis']=='M').astype(int))

#setting variables
X=df.iloc[:,2:32]
y=df.iloc[:,32]

#splitting data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)

#normalizing data because attributes have different ranges
sc = StandardScaler()
sc.fit(X_train)

X_train_std = sc.transform(X_train) 
X_test_std = sc.transform(X_test) 

"""Create an ROC curve for k-NN, decision tree, and logistic regression. Discuss the results. Which classifier would you prefer to choose? 
Please provide screenshots of your code and explain the process you have followed.
Specific Tasks:
Correct visualization of ROC graph for kNN – use optimal kNN from part a
Correct visualization of ROC graph for Decision Tree – use optimal Decision Tree from part a
Correct visualization of ROC graph for Logistic Regression – use optimal Logistic Regression from part a
Show all the ROC graphs in one single plot
Show AUC estimators in the ROC graph
Discuss and correctly identify which classifier you would use"""

#normalizing data because attributes have different ranges
sc = StandardScaler()
sc.fit(X_train)

X_train_std = sc.transform(X_train) 
X_test_std = sc.transform(X_test) 

######################################## Classifiers ########################################
# Logistic Regression Classifier
clf1 = LogisticRegression(penalty='l1', 
                          C=100,
                          random_state=42, 
                          solver='liblinear') 

# Decision Tree Classifier
clf2 = DecisionTreeClassifier(max_depth=5,
                              criterion='gini',
                              random_state=42,
                              min_samples_leaf=6,
                              min_samples_split=2)

# kNN Classifier
clf3 = KNeighborsClassifier(n_neighbors=9,
                            p=2,
                            metric='minkowski',
                            weights='uniform')

# Label the classifiers
clf_labels1 = ['Logistic regression', 'Decision tree']
all_clf1 = [clf1, clf2]
clf_labels2 = ['kNN']
all_clf2 = [clf3]
##################################### Visualization ######################################
colors1 = [ 'orange', 'blue', 'green']      # Colors for visualization
linestyles1 = [':', '--', '-.', '-']        # Line styles for visualization
#ROC curve for decision tree, logit
for clf, label, clr, ls in zip(all_clf1,
               clf_labels1, colors1, linestyles1):

    # Assuming the label of the positive class is 1 and data is normalized
    y_pred = clf.fit(X_train,
                     y_train).predict_proba(X_test)[:, 1] # Make predictions based on the classifiers
    fpr, tpr, thresholds = roc_curve(y_true=y_test, # Build ROC curve
                                     y_score=y_pred)
    roc_auc = auc(x=fpr, y=tpr)                # Compute Area Under the Curve (AUC) 
    plt.plot(fpr, tpr,                         # Plot ROC Curve and create label with AUC values
             color=clr,
             linestyle=ls,
             label='%s (auc = %0.2f)' % (label, roc_auc))

plt.legend(loc='lower right')    # Where to place the legend
plt.plot([0, 1], [0, 1], # Visualize random classifier
         linestyle='--',
         color='gray',
         linewidth=2)

#ROC curve for k-NN
colors2 = ['green']      # Colors for visualization
linestyles2 = ['-']        # Line styles for visualization
for clf, label, clr, ls in zip(all_clf2,
               clf_labels2, colors2, linestyles2):

    # Assuming the label of the positive class is 1 and data is normalized
    y_pred = clf.fit(X_train_std,
                     y_train).predict_proba(X_test_std)[:, 1] # Make predictions based on the classifiers
    fpr, tpr, thresholds = roc_curve(y_true=y_test, # Build ROC curve
                                     y_score=y_pred)
    roc_auc = auc(x=fpr, y=tpr)                # Compute Area Under the Curve (AUC) 
    plt.plot(fpr, tpr,                         # Plot ROC Curve and create label with AUC values
             color=clr,
             linestyle=ls,
             label='%s (auc = %0.2f)' % (label, roc_auc))

plt.legend(loc='lower right')    # Where to place the legend
plt.plot([0, 1], [0, 1], # Visualize random classifier
         linestyle='--',
         color='gray',
         linewidth=2)

plt.xlim([-0.1, 1.1])   #limits for x axis
plt.ylim([-0.1, 1.1])   #limits for y axis
plt.grid(alpha=0.5)
plt.xlabel('False positive rate (FPR)')
plt.ylabel('True positive rate (TPR)')


#plt.savefig('ROC_all_classifiers', dpi=300)
plt.show()